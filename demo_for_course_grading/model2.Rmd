---
title: "Demo of Model 2"
subtitle: "(Run on a subset of the data)"
author: "Thanasi Bakis, Anjali Krishnan"
---

<style type="text/css">
  code {
    font-family: "Fira Code Retina", monospace;
  }
</style>
  
```{r libraries, warning=FALSE, include=FALSE, message=FALSE}
library(magrittr)
library(plotROC)
library(tidyverse)
library(randomForest)
library(glmnet)
library(extrafont)
library(DBI)
library(here)
```


```{r save_parameters, include=FALSE}
DATASET_FILE <- "dataset_20MB.csv"
API_KEYS_FILE <- "api_keys.py"
TT_SPLIT_FILE <- "demo_ttsplit_save.rda"
FEATURES_FILE <- "demo_features_save.rda"
MODEL_FILE <- "demo_model_fit_save.rda"
```

<br>
Retrieve the data saved from the database

```{r load_dataset, message=FALSE, warning=FALSE}
if(file.exists(DATASET_FILE)) {
  
  dataset <- read_csv(DATASET_FILE)
  
} else {
  
  source(API_KEYS_FILE)
  
  con <- dbConnect(
    RPostgres::Postgres(),
    host = SQL_HOST,
    dbname = SQL_DB,
    user = SQL_USER,
    password = SQL_PASS
  )
  
  dataset <- tbl(con, "dataset") %>%
    filter(lastpos != 0) %>% # songs on the charts for the first time haven't changed rank
    collect()
  
  dbDisconnect(con)
  write_csv(dataset, DATASET_FILE)
  
}
```

<br>
Our interaction terms will be defined as principal components (linear combinations of the original features)

```{r}
if(file.exists(FEATURES_FILE)) {
  
  load(FEATURES_FILE)
  
} else {
  
  PCA <- dataset %>%
  	select(songpositivity,   songnegativity, songneutrality, songsentiment,
  		     acousticness,     danceability,   duration_ms,    energy,
  		     instrumentalness, key,            liveness,       loudness,
  		     mode,             speechiness,    tempo,          time_signature,
  		     valence,          peakpos,        weeks,          lastpos,
  		     starts_with(c("songmin", "songmax")),
  
  		     newspositivity,   newsnegativity, newsneutrality, newssentiment,
  		     starts_with(c("newsmin", "newsmax"))) %>%
  	prcomp()
  
  features <- PCA %>%
  	magrittr::extract2("x") %>%
  	as.data.frame() %>%
    mutate(response = factor(dataset$rank < dataset$lastpos))
  
  save(features, file = FEATURES_FILE)
  
}
```

<br>
Generate the model formula

```{r}
formula <- features %>%
  select(-response) %>%
  colnames() %>%
	paste(collapse = " + ") %>%
	paste("response ~", . )
```

<br>
Train-test split

```{r message=FALSE, warning=FALSE}
if(file.exists(TT_SPLIT_FILE)) {
  
  load(TT_SPLIT_FILE)
  
} else {
  
  training_data <- features %>%
  sample_frac(0.5)

  testing_data <- anti_join(features, training_data)
  
  save(training_data, testing_data, file = TT_SPLIT_FILE)
  
}

```

<br>
Fit the model

```{r message=FALSE, warning=FALSE}
if(file.exists(MODEL_FILE)) {
  
  load(MODEL_FILE)
  
} else {
  
  model <- cv.glmnet(
    as.matrix(select(training_data, -response)),
    pull(training_data, response),
    family = "binomial"
  )
  
  save(model, file = MODEL_FILE)
  
}
```

<br>
How many features did the model keep?

```{r}
plot(model)
coef(model)@i # index 1 (value 0) is the intercept

# https://stackoverflow.com/questions/29311323
```

<br>
Make predictions and assess accuracy

```{r}
predictions <- testing_data %>%
	mutate(soft_prediction = predict(model, newx = as.matrix(select(., -response)), type = "response")) %>%
	mutate(hard_prediction = soft_prediction >= 0.5) %>%
	mutate(is_correct      = hard_prediction == response)

paste("Accuracy: ", 100*round(mean(predictions$is_correct), 4), "%", sep = '')
```

<br>
What is our test data's response distribution?
What is our model's prediction distribution?

```{r}
predictions %>%
	select(response, hard_prediction) %>%
  mutate(response = as.logical(response),
         hard_prediction = as.logical(hard_prediction)) %>% # un-factorize if necessary
	pivot_longer(
		c(response, hard_prediction),
		names_to = "Type",
		values_to = "Value"
	) %>%
	ggplot(aes(x = Value)) +
	geom_bar(aes(fill = Value)) +
	ylim(0, nrow(predictions)) +
	facet_wrap(
		~ Type,
		labeller = labeller(Type = c(hard_prediction = "Model Prediction", response = "True Value"))
	) +
	labs(title = "Distribution of response values and predictions") +
  theme(
    legend.position = "none",
    text = element_text(size = 14, family = "Roboto Light"),
    plot.title = element_text(size = 20)
  )
```

<br>
How good are the hard predictions?

```{r}
predictions %>%
	ggplot(aes(x = response, fill = hard_prediction)) +
	geom_bar(position = position_dodge()) +
	ylim(0, nrow(testing_data)) +
	labs(
	  x = "True Response Value",
	  fill = "Model Prediction",
	  title = "Distribution of model predictions",
	  subtitle = "by response value"
	) +
  theme(
    text = element_text(size = 14, family = "Roboto Light"),
    plot.title = element_text(size = 20)
  )
```

<br>
How good are the soft predictions?
  
```{r}
predictions %>%
  ggplot(aes(y = soft_prediction, x = response)) +
  geom_boxplot(fill = "#F8867D") +
  labs(
    x = "Response Value",
    y = "Model Predicted Probability",
    title = "Distribution of model soft predictions",
    subtitle = "by response value"
  ) +
  theme(
    text = element_text(size = 14, family = "Roboto Light"),
    plot.title = element_text(size = 20)
  )
```

<br>
ROC curve to figure out which soft-->hard cutoff to use

```{r warning=FALSE}
roc <- predictions %>%
  ggplot(aes(m = soft_prediction, d = response)) +
  geom_roc(n.cuts = 20, labels = T, labelround = 2) +
  geom_abline(a = 1, b = 0) +
  labs(
    x = "False Positive Rate",
    y = "True Positive Rate",
    title = "ROC Curve"
  ) +
  theme(
    text = element_text(size = 14, family = "Roboto Light"),
    plot.title = element_text(size = 20)
  )

roc
```

<br>
Calculate the AUC

```{r message=FALSE, warning=FALSE}
calc_auc(roc)$AUC
```

